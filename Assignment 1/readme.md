# ðŸ“Š Pandas Basics Assignment: Data Analysis 

This document summarizes the core tasks, data manipulation techniques, and essential Pandas functions used to complete the data analysis questions on the Russian retail data (Kaggle Final Project dataset).

-----

## I. Data Loading and Setup

The assignment began by loading four key DataFrames and inspecting their structure and contents:

| DataFrame | Description | Key Columns |
| :--- | :--- | :--- |
| `transactions` | Daily sales data for all shops/items. | `date`, `shop_id`, `item_id`, `item_price`, `item_cnt_day` |
| `items` | Item metadata. | `item_id`, `item_category_id` |
| `item_categories` | Item category names. | `item_category_id`, `item_category_name` |
| `shops` | Shop metadata. | `shop_id`, `shop_name` |

### **Initial Data Processing Steps**

1.  **Date Conversion:** The `date` column in the `transactions` DataFrame was converted to the `datetime` format to facilitate filtering and feature extraction.
    ```python
    df['date'] = pd.to_datetime(df['date'], format='%d.%m.%Y') #
    ```
2.  **Date Feature Extraction:** New columns (`day`, `month`, `year`) were created from the `date` column for filtering.
    ```python
    df['day'] = df['date'].dt.day #
    df['month'] = df['date'].dt.month #
    df['year'] = df['date'].dt.year #
    ```
3.  **Revenue Calculation:** A new column, `revenue`, was calculated for each transaction. This column handles sales and returns (where `item_cnt_day` is negative).
    ```python
    df['revenue'] = df['item_price'] * df['item_cnt_day'] #
    ```

-----

## II. Key Pandas Functions Template

The following essential Pandas functions were repeatedly used throughout the assignment:

| Function/Method | Primary Purpose | Example Syntax |
| :--- | :--- | :--- |
| `pd.read_csv()` | Load data from CSV files. | `pd.read_csv('file.csv')` |
| `pd.to_datetime()` | Convert date columns to datetime objects. | `pd.to_datetime(df['date'], ...)` |
| `df.query()` | Filter a DataFrame using boolean expressions. | `df.query('month == 9 and year == 2014')` |
| `pd.merge()` | Combine DataFrames based on common columns (joins). | `pd.merge(df1, df2, on='key', how='left')` |
| `df.groupby()` | Group data by one or more columns for aggregation. | `df.groupby('shop_id')['revenue'].sum()` |
| `.dt.month`/`.dt.year` | Extract month/year from a datetime column. | `df['date'].dt.month` |
| `.sum()`/`.nunique()` | Aggregate functions (sum, count unique values). | `['revenue'].sum()` |
| `.max()`/`.idxmax()` | Find the maximum value or the index label where the maximum occurs. | `revenue_per_shop.max()` |
| `.var(ddof=1)` | Compute the unbiased variance ($\text{ddof}=1$ is for sample variance). | `res.var(ddof=1)` |

-----

## III. Detailed Solution Steps

### **1. Maximum Total Revenue in September 2014**

**Goal:** Find the maximum total `revenue` generated by any single `shop_id` in September 2014.

| Step | Action | Pandas Technique |
| :--- | :--- | :--- |
| **1** | Filter transactions for **September 2014** (`month == 9` and `year == 2014`). | `df.query()` |
| **2** | Group the filtered results by **`shop_id`**. | `.groupby('shop_id')` |
| **3** | Calculate the **total revenue** for each shop. | `['revenue'].sum()` |
| **4** | Find the maximum value from the resulting series. | `.max()` |

**Result:** Max Revenue: **$7,982,852.200**

-----

### **2. Highest Revenue Item Category in Summer 2014**

**Goal:** Find the `item_category_id` that generated the highest total `revenue` during summer 2014 (June, July, August).

| Step | Action | Pandas Technique |
| :--- | :--- | :--- |
| **1** | Filter transactions for **Summer 2014** (`month` $\in [6, 7, 8]$ and `year == 2014`). | `df.query()` |
| **2** | **Join** the filtered transactions with the `items` table on `item_id` to get `item_category_id`. | `pd.merge(..., on='item_id', how='left')` |
| **3** | Group the joined data by **`item_category_id`**. | `.groupby('item_category_id')` |
| **4** | Calculate the **total revenue** for each category. | `['revenue'].sum()` |
| **5** | Find the **index** (`item_category_id`) corresponding to the maximum revenue. | `.idxmax()` |

**Result:** Highest Revenue Category ID: **20**

-----

### **3. Count of Items with Constant Price**

**Goal:** Count how many unique items (`item_id`) maintain a single constant price throughout the dataset.

| Step | Action | Pandas Technique |
| :--- | :--- | :--- |
| **1** | Group all transactions by **`item_id`**. | `df.groupby('item_id')` |
| **2** | Calculate the **number of unique prices** (`item_price`) for each item. | `['item_price'].nunique()` |
| **3** | Filter the resulting series where the count of unique prices is exactly **1**. | `item_prices[item_prices == 1]` |
| **4** | Count the total number of items in the final filtered series. | `len(...)` |

**Result:** Number of items with constant price: **5926**

-----

### **4. Variance of Sold Items in December 2014 for Shop 25**

**Goal:** Calculate the **unbiased variance** of the sequence of total items sold per day for `shop_id = 25` in December 2014.

| Step | Action | Pandas Technique |
| :--- | :--- | :--- |
| **1** | Filter for transactions for **Shop 25** in **December 2014**. | `df.query('month == 12 and year == 2014 and shop_id == 25')` |
| **2** | Group the filtered results by **`date`**. | `.groupby('date')` |
| **3** | Sum the **`item_cnt_day`** for each day to get the daily sales sequence. | `['item_cnt_day'].sum()` |
| **4** | Compute the **unbiased variance** of the daily sales sequence. | `.var(ddof=1)` |

**Result:** Unbiased Variance: **117,167.702**
